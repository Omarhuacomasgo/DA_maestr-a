---
title: "An√°lisis de datos ‚Äì tesis de maestr√≠a"
author: "Omar Huaco"
date: last-modified     # se actualiza al compilar
lang: es
execute:
  warning: false        # suprime advertencias
  message: false        # suprime mensajes
  echo: true            # (opcional) muestra el c√≥digo
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: true
    code-overflow: scroll
    df-print: paged
    highlight-style: github
---


```{r}
#| label: setup
#| include: false

knitr::opts_knit$set(
  echo = TRUE,               # muestra el c√≥digo
  warning = FALSE,           # no muestra advertencias
  message = FALSE,           # no muestra mensajes
  fig.width = 8,            # ancho de las figuras
  fig.height = 5,           # alto de las figuras
  fig.align = "center",    # alinea las figuras al centro
  dpi = 300)           # resoluci√≥n de las figuras
  
```


# Resumen 

Este informe reconstruye el an√°lisis de datos ejecutado para el proyecto de tesis

```{r, message = FALSE, results= 'hide'}

lapply(c("tidyverse", "readxl", "writexl", "modelsummary", "haven", "janitor", "labelled", "forcats"), library, 
       character.only = TRUE)

```

# Carga de datos y data wrangling

En esta secci√≥n se carga el conjunto de datos del Latinobar√≥metro 2023 y se realiza un preprocesamiento b√°sico para su an√°lisis.

```{r, message = FALSE, results = 'hide'}
#| label: load-data
#| include: true

lb2023 <- haven :: read_sav("E:\\Bases de datos\\latinobarometro_datasets\\lb2023.sav")
```


```{r, message = FALSE, results = 'hide'}
lb2023 <- lb2023 %>%  mutate(across(where(is.character), trimws)) %>% 
  rename_with(~ gsub("[._[:space:]]+", "", tolower(.x)))

```

La base de datos global contiene metadatos que describen las variables, como etiquetas y valores. Para explorar estos metadatos, se utiliza la funci√≥n `look_for` del paquete `labelled`.

```{r, message = FALSE}
# 1. Exploraci√≥n de los metadatos
lb2023_metadata <- look_for(lb2023) %>% as_tibble()
lb2023_metadata
```


```{r, message = FALSE}
# 2. Exporta a Excel con writexl
writexl::write_xlsx(x = lb2023, path = file.path("Exports", "Tables", "lb2023.xlsx"))
```

# Preparacion de datos

## Definici√≥n de listas de variables

Extraemos las variables de inter√©s en listas que podemos editar posteriormente. En este caso, se extraen las variables dependientes e independientes que se utilizar√°n en el an√°lisis.

Podemos crear una lista de varibles dependientes clasificandolas segun su rol en nuestros modelos. Por ejemplo,`principal_predictors` son las variables principales que se espera que tengan un efecto significativo en la variable dependiente, mientras que `sociodem_controls` y `other_controls` son variables de control que se incluir√°n para ajustar el modelo y controlar por posibles confusores.

Con `var_lists` se agrupan todas las variables en una lista para facilitar su manejo y edici√≥n posterior, luego con `all_of` se seleccionan las variables de la base de datos previamente almacenadas en `var_lists`.

```{r}
#| label: extract-data
#| include: true

# Variable dependiente
dep_vars <- c("p13std")  # Confianza en el Congreso

# Predictores principales (editables)
principal_predictors <- c(
  "p18sta",   # Problemas en la democracia
  "p18sti",   # La democracia soluciona problemas
  "p18ne",    # Poder judicial independiente
  "p54na",    # Tolerancia a la protesta
  "p11stgbsa",# Satisfacci√≥n con la democracia
  "p11stgbsb" # Satisfacci√≥n con la econom√≠a
)

sociodem_controls <- c(
  "edad",     # Edad 
  "sexo",
  "s1",       # Religi√≥n
  "s1a",      # Practica religiosa
  "s2",       # Clase social subjetiva
  "s7",       # Raza
  "s18a"      # Ocupaci√≥n
)
# Otras variabels de control
other_controls <- c(
  "p16st",    # Eje izquierda‚Äìderecha
  "p17st",    # Cu√°n justa es la distribuci√≥n de ingreso
  "reg",      # Regi√≥n
  ## Variables asociadas al dise√±o muestral
  "ciudad",   # Ciudad
  "tamciud",  # Tama√±o de la ciudad
  "idenpa",   # Pa√≠s
  "wt"    # Ponderaci√≥n muestral
)

# Agrupar todo en una lista para f√°cil acceso
var_lists <- list(
  dep_vars             = dep_vars,
  principal_predictors = principal_predictors,
  sociodem_controls    = sociodem_controls,
  other_controls       = other_controls
)

# Seleccionar todas las variables relevantes
lb2023_a <- lb2023 %>% select(
    all_of(var_lists$dep_vars),
    all_of(var_lists$principal_predictors),
    all_of(var_lists$sociodem_controls),
    all_of(var_lists$other_controls))
```


```{r}
lb2023_a <- lb2023_a %>%
  mutate(
    edad = as.numeric(edad)  # conservar edad como num√©rica
  ) %>%
  mutate(
    across(
      .cols = where(haven::is.labelled),
      .fns  = ~ haven::as_factor(.x, levels = "labels")
    )
  )
```


# Procesamiento de niveles de variables categoricas

Generamos una lista del universo de categor√≠as ordinales que utiliza el latinobarometro en sus encuestas. Nos aseguramos que R reconozca estas variables como factores ordenados.

```{r}
# Listas de niveles ordinales est√°ndar
ord_foursteps <- c("Ninguna", "Poca", "Algo", "Mucha")
cs_subjective_ord <- c("Baja", "Media Baja", "Media", "Media Alta", "Alta")
justice_ord <- c("Muy injusta", "Injusta", "Justa", "Muy justa")
ord_satis     <- c("Nada satisfecho", "No muy satisfecho", "Mas bien satisfecho", "Muy satisfecho")
ord_agree     <- c("Muy en desacuerdo", "En desacuerdo", "De acuerdo", "Muy de acuerdo")
unknown_cat   <- c("No sabe", "No contesta", "No aplicable", "No preguntada", "No sabe / No contesta")
```

```{r}
# Recodificar todas las variables ordinales de manera unificada:
lb2023_a <- lb2023_a %>%
  mutate(
    across(
      .cols = where(is.factor),
      .fns = ~ {
        x_chr <- as.character(.x)
        # Marcar datos desconocidos como NA
        x_chr[x_chr %in% unknown_cat] <- NA
        # Identificar y aplicar niveles
        if (all(na.omit(x_chr) %in% ord_foursteps)) {
          factor(x_chr, levels = ord_foursteps, ordered = TRUE)
        } else if (all(na.omit(x_chr) %in% cs_subjective_ord)) {
          factor(x_chr, levels = cs_subjective_ord, ordered = TRUE)
        } else if (all(na.omit(x_chr) %in% justice_ord)) {
          factor(x_chr, levels = justice_ord, ordered = TRUE)
        } else if (all(na.omit(x_chr) %in% ord_satis)) {
          factor(x_chr, levels = ord_satis, ordered = TRUE)
        } else if (all(na.omit(x_chr) %in% ord_agree)) {
          factor(x_chr, levels = ord_agree, ordered = TRUE)
        } else {
          # Devolver original si no coincide con ninguna escala
          .x
        }
      }
    )
  )
```

Procesamos por separado algunas variables especiales. 

```{r, warning=FALSE, message=FALSE}
# Recodificaci√≥n espec√≠fica de p16st (eje izquierda‚Äìderecha) en un bloque aparte
lb2023_a <- lb2023_a %>%
  mutate(
    p16st = case_when(
      grepl("^00", p16st)                 ~ 0L,
      grepl("^10", p16st)                 ~ 10L,
      p16st %in% as.character(1:9)       ~ as.integer(as.character(p16st)),
      TRUE                                ~ NA_integer_
    )
  )

```


Finalmente, filtramos las observaciones a Per√∫

```{r}
lb2023_pe <- lb2023_a %>% filter(idenpa == " Peru") 
```


# Analisis de valores perdidos

## Estad√≠sticos de resumen 

En esta secci√≥n, se analiza univariadamente cada variable del dataset. Comprobamos que las variables categ√≥ricas tengan los niveles correctos y que las variables num√©ricas est√©n en el formato adecuado. 
Se identifican los valores perdidos y se proporciona un resumen de las variables.

```{r}
library(skimr)
skimr :: skim(lb2023_pe) %>% as_tibble()
```

```{r}
library(naniar)
naniar :: vis_miss(lb2023_pe)
```
# Imputaci√≥n rapida
```{r, warning=FALSE, message=FALSE}
library(mice)
# 1. Identificar columnas con NA
cols_na <- names(which(colSums(is.na(lb2023_pe)) > 0))
```

Clasificamos las variables seg√∫n su tipo para aplicar m√©todos de imputaci√≥n adecuados. Las variables num√©ricas, ordinales y categ√≥ricas se manejan de manera diferente en el proceso de imputaci√≥n.

```{r}
# 2. Clasificar variables
numeric_vars    <- cols_na[sapply(lb2023_pe[cols_na], is.numeric)]
ordinal_vars    <- cols_na[sapply(lb2023_pe[cols_na], is.ordered)]
categorical_vars <- cols_na[sapply(lb2023_pe[cols_na], function(x) is.factor(x) && !is.ordered(x))]
```

Le decimos a R que en meth_vec vamos a definir los m√©todos de imputaci√≥n para cada tipo de variable. Utilizamos `make.method` del paquete `mice` para crear un vector de m√©todos de imputaci√≥n. Luego, asignamos el m√©todo adecuado a cada tipo de variable.

```{r}
# 3. Definir m√©todos de imputaci√≥n para MICE
meth_vec <- make.method(lb2023_pe[cols_na])

meth_vec[numeric_vars]    <- "pmm"     # Predictive Mean Matching para num√©ricas
meth_vec[ordinal_vars]    <- "polr"    # Proportional Odds Logistic Regression para ordinales
meth_vec[categorical_vars] <- "polyreg" # Regresi√≥n polin√≥mica para nominales
```

Ejecutamos el proceso de imputaci√≥n multivariada utilizando la funci√≥n `mice`. Especificamos el n√∫mero de imputaciones (`m = 10`) y un valor de semilla para la reproducibilidad (`seed = 123`). La opci√≥n `printFlag = FALSE` suprime la salida de progreso.

```{r}
# 4. Ejecutar imputaci√≥n multivariada
imp_full <- mice(lb2023_pe[cols_na], method = meth_vec, m = 10, seed = 123, printFlag = FALSE)

# 5. Completar base con la primera imputaci√≥n (puede cambiarse a pool)
lb2023_pe_imp <- lb2023_pe
lb2023_pe_imp[cols_na] <- complete(imp_full, 1)

# 6. Resumen r√°pido de columnas imputadas
tibble(
  tipo        = c("Num√©ricas", "Ordinales", "Nominales"),
  n_variables = c(length(numeric_vars), length(ordinal_vars), length(categorical_vars))
)

```

```{r}
lb2023_pe <- lb2023_pe_imp
skimr :: skim(lb2023_pe) %>% as_tibble()
```
# Modelamiento

## Las regresiones log√≠sticas ordinales

Las regresiones log√≠sticas ordinales resultan id√≥neas cuando la variable de inter√©s toma valores ordenados (por ejemplo niveles de satisfacci√≥n o confianza) sin que la distancia entre ellos sea necesariamente constante. En tu caso, la confianza en el Congreso (p13std) se modela en funci√≥n de un conjunto de predictores ùë•, capturando el car√°cter ordinal de las categor√≠as. Matem√°ticamente, para una variable ùëåcon ùêæ niveles (1,2,‚Ä¶,ùêæ) el modelo de probabilidades acumuladas se expresa como:

Para cada \(k=1,\dots,K-1\):

$$
\Pr(Y \le k \mid x) = \frac{1}{1 + \exp\bigl(-(\alpha_k - x^\top\beta)\bigr)}.
$$

Equivalentemente,

$$
\log\frac{\Pr(Y \le k \mid x)}{\Pr(Y > k \mid x)}
=\alpha_k - x^\top\beta.
$$


## Especificacion de modelos

```{r, message=FALSE, warning=FALSE}

library(MASS)   # polr()
library(broom)  # tidy / glance
library(purrr)  # map / imap

# Modelo 1: S√≥lo predictores principales
mod_ord1 <- polr(
  p13std ~ p18sta + p18sti + p18ne + p54na + p11stgbsa + p11stgbsb,
  data    = lb2023_pe,
  weights = wt,
  Hess    = TRUE
)

# Modelo 2: + controles sociodemogr√°ficos
mod_ord2 <- polr(
  p13std ~ p18sta + p18sti + p18ne + p54na + p11stgbsa + p11stgbsb + edad + sexo + s2,
  data    = lb2023_pe,
  weights = wt,
  Hess    = TRUE
)

# Modelo 3: + variables pol√≠tico-ideol√≥gicas y de contexto
mod_ord3 <- polr(p13std ~ p18sta + p18sti + p18ne + p54na + p11stgbsa + p11stgbsb + 
                   edad + sexo + s2 + 
                   p16st + p17st,
  data    = lb2023_pe,
  weights = wt,
  Hess    = TRUE
)

```


```{r}
tab_ord1 <- tidy(mod_ord1, conf.int = TRUE) %>%
  mutate(
    OR       = exp(estimate),      # convierte log-odds en odds ratio
    p.value  = 2 * (1 - pnorm(abs(statistic))),
    signif   = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE            ~ ""
    )
  ) %>% dplyr::  select(term, estimate, OR, std.error, statistic, p.value, signif, conf.low, conf.high)

tab_ord2 <- tidy(mod_ord2, conf.int = TRUE) %>%
  mutate(
    OR       = exp(estimate),      # convierte log-odds en odds ratio
    p.value  = 2 * (1 - pnorm(abs(statistic))),
    signif   = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE            ~ ""
    )
  ) %>% dplyr ::  select(term, estimate, OR, std.error, statistic, p.value, signif, conf.low, conf.high)

tab_ord3 <- tidy(mod_ord3, conf.int = TRUE) %>%
  mutate(
    OR       = exp(estimate),      # convierte log-odds en odds ratio
    p.value  = 2 * (1 - pnorm(abs(statistic))),
    signif   = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE            ~ ""
    )
  ) %>% dplyr:: select(term, estimate, OR, std.error, statistic, p.value, signif, conf.low, conf.high)

#tab_ordx %>% as_tibble()
```


`
```{r}
# Mostrar tabla con gt (Quarto friendly)
library(gt)
tab_ord1 %>%
  gt() %>%
  tab_header(
    title = md("**Tabla de resultados mod_ord1**"),
    subtitle = md("Coeficientes (log-odds), OR, p-values y significancia")
  ) %>%
  fmt_number(
    columns = vars(estimate, OR, std.error, statistic, p.value, conf.low, conf.high),
    decimals = 2
  ) %>%
  cols_label(
    term       = "Predictor",
    estimate   = "Coef",
    OR         = "OR",
    std.error  = "SE",
    statistic  = "z",
    p.value    = "p",
    signif     = "Signif",
    conf.low   = "IC 2.5%",
    conf.high  = "IC 97.5%"
  ) %>%
  tab_source_note(md("Signif.: * p<0.05; ** p<0.01; *** p<0.001"))

```


```{r}
# Mostrar tabla con gt (Quarto friendly)
library(gt)
tab_ord2 %>%
  gt() %>%
  tab_header(
    title = md("**Tabla de resultados mod_ord2**"),
    subtitle = md("Coeficientes (log-odds), OR, p-values y significancia")
  ) %>%
  fmt_number(
    columns = vars(estimate, OR, std.error, statistic, p.value, conf.low, conf.high),
    decimals = 2
  ) %>%
  cols_label(
    term       = "Predictor",
    estimate   = "Coef",
    OR         = "OR",
    std.error  = "SE",
    statistic  = "z",
    p.value    = "p",
    signif     = "Signif",
    conf.low   = "IC 2.5%",
    conf.high  = "IC 97.5%"
  ) %>%
  tab_source_note(md("Signif.: * p<0.05; ** p<0.01; *** p<0.001"))

```


```{r}
# Mostrar tabla con gt (Quarto friendly)
library(gt)
tab_ord3 %>%
  gt() %>%
  tab_header(
    title = md("**Tabla de resultados mod_ord1**"),
    subtitle = md("Coeficientes (log-odds), OR, p-values y significancia")
  ) %>%
  fmt_number(
    columns = vars(estimate, OR, std.error, statistic, p.value, conf.low, conf.high),
    decimals = 2
  ) %>%
  cols_label(
    term       = "Predictor",
    estimate   = "Coef",
    OR         = "OR",
    std.error  = "SE",
    statistic  = "z",
    p.value    = "p",
    signif     = "Signif",
    conf.low   = "IC 2.5%",
    conf.high  = "IC 97.5%"
  ) %>%
  tab_source_note(md("Signif.: * p<0.05; ** p<0.01; *** p<0.001"))

```


Si deseas ver las tablas en formato apa, puedes usar el siguiente codigo
```{r}
library(modelsummary)

# Construir lista de modelos con etiquetas
models_list <- list(
  "Modelo 1" = mod_ord1,
  "Modelo 2" = mod_ord2,
  "Modelo 3" = mod_ord3
)

# Generar tabla APA
modelsummary(
  models_list,
  output = "kableExtra",    # Salida en HTML para Quarto
  stars  = TRUE,             # Estrellas de significancia
  fmt    = 2,                # Dos decimales
  style  = "apa",          # Formato APA
  coef_omit = "(Intercept)", # Omitir interceptos si se desea
  title  = "Tabla APA de modelos de regresi√≥n ordinal"
) %>%
  kableExtra::kable_styling(full_width = FALSE)
```
```

